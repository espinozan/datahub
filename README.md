## En Desarrollo no esta listo para prod. 

# DataHub: Sistema Unificado de GestiÃ³n de Datasets para InvestigaciÃ³n en IA

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ğŸ¯ VisiÃ³n General

**DataHub** es una plataforma de cÃ³digo abierto diseÃ±ada especÃ­ficamente para cientÃ­ficos e investigadores en Inteligencia Artificial que necesitan descubrir, filtrar, descargar y gestionar datasets de manera eficiente. El sistema unifica mÃºltiples fuentes de datos bajo una arquitectura REST API basada en FastAPI.

### CaracterÃ­sticas Principales

- ğŸ” **BÃºsqueda Unificada**: IntegraciÃ³n con Hugging Face, Kaggle, GitHub y Google Drive
- ğŸ§  **BÃºsqueda SemÃ¡ntica**: Ranking hÃ­brido con BM25 y embeddings
- âš¡ **Descarga Paralela**: OrquestaciÃ³n eficiente con retry automÃ¡tico
- ğŸ“Š **Analytics Avanzados**: MÃ©tricas de calidad y distribuciÃ³n de datos
- ğŸ”Œ **Sistema de Plugins**: Arquitectura extensible para nuevos proveedores
- ğŸ¨ **Interface Web**: React + TypeScript con UI moderna
- ğŸ“ˆ **Observabilidad**: Monitoring completo con Prometheus y Grafana

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CAPA DE PRESENTACIÃ“N                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Web UI      â”‚  â”‚  REST API    â”‚  â”‚  CLI Tool    â”‚      â”‚
â”‚  â”‚  (React)     â”‚  â”‚  (FastAPI)   â”‚  â”‚  (Typer)     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE LÃ“GICA DE NEGOCIO                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Dataset Discovery & Management Engine         â”‚   â”‚
â”‚  â”‚  â€¢ Semantic Search    â€¢ Filter Pipeline              â”‚   â”‚
â”‚  â”‚  â€¢ Metadata Indexing  â€¢ Download Orchestrator        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CAPA DE ADAPTADORES (Plugins)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ HuggingFace â”‚ â”‚   Kaggle    â”‚ â”‚   GitHub    â”‚          â”‚
â”‚  â”‚  Adapter    â”‚ â”‚   Adapter   â”‚ â”‚   Adapter   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE PERSISTENCIA                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  PostgreSQL  â”‚  â”‚   Redis      â”‚  â”‚  MinIO/S3    â”‚      â”‚
â”‚  â”‚  (Metadata)  â”‚  â”‚  (Cache)     â”‚  â”‚  (Storage)   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisitos

- Python 3.11+
- PostgreSQL 15+
- Redis 7+
- Docker & Docker Compose (opcional)

### InstalaciÃ³n

```bash
# Clonar repositorio
git clone https://github.com/espinozan/datahub.git
cd datahub

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# Ejecutar migraciones
alembic upgrade head

# Iniciar servicios
docker-compose up -d postgres redis minio

# Iniciar servidor
uvicorn app.main:app --reload
```

### Uso RÃ¡pido

```python
from datahub import DataHub

# Inicializar cliente
hub = DataHub(api_key="your_api_key")

# BÃºsqueda de datasets
results = hub.search(
    query="code generation python",
    filters={
        "domain": ["code", "nlp"],
        "size_min": 10000,
        "license": ["mit", "apache-2.0"]
    }
)

# Descargar dataset
job = hub.download(
    dataset_id="deepmind/code_contests",
    provider="huggingface",
    splits=["train", "validation"]
)

# Monitorear progreso
for update in job.progress():
    print(f"Progress: {update.percent}%")
```

## ğŸ“š DocumentaciÃ³n Completa

- [GuÃ­a de Arquitectura](docs/ARCHITECTURE.md)
- [API Reference](docs/API.md)
- [GuÃ­a de Desarrollo](docs/DEVELOPMENT.md)
- [Sistema de Plugins](docs/PLUGINS.md)
- [Deployment Guide](docs/DEPLOYMENT.md)

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest

# Tests con coverage
pytest --cov=app --cov-report=html

# Tests de integraciÃ³n
pytest tests/integration/

# Tests de performance
pytest tests/performance/ --benchmark
```

## ğŸ¤ ContribuciÃ³n

Contribuciones son bienvenidas! Por favor lee nuestra [GuÃ­a de ContribuciÃ³n](CONTRIBUTING.md) para detalles sobre nuestro cÃ³digo de conducta y el proceso para enviar pull requests.

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo Apache License 2.0 - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ™ Agradecimientos

- Hugging Face por su excelente ecosistema de datasets
- FastAPI por el framework web de alto rendimiento
- La comunidad de investigaciÃ³n en IA

## ğŸ“ Contacto

- Email: contact@datahub.ai
- Discord: [DataHub Community](https://discord.gg/datahub)
- Twitter: [@DataHubAI](https://twitter.com/DataHubAI)

---

**Desarrollado con â¤ï¸ por el equipo de Ainsophic - DataHub Engineering**
